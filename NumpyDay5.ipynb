{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd4cac31",
   "metadata": {},
   "source": [
    "__Day 5__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7755c0",
   "metadata": {},
   "source": [
    "__Core Mathematical functions__ :\n",
    "\n",
    "__Used In Ml and DL__ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24dc0f5",
   "metadata": {},
   "source": [
    "1. __Sigmoid Function__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ff6b29",
   "metadata": {},
   "source": [
    "The Sigmoid function maps any real number to a value between 0 and 1.\n",
    "\n",
    "Formula:\n",
    "      \n",
    "$$\\Large \\sigma( x) = \\frac{1}{1 + e^{-x}}$$\n",
    "\n",
    "It \"squashes\" input values into a smooth curve.\n",
    "\n",
    "Often used to represent probability (e.g., output of a binary classifier).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "954be90d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nSigmoid Curve Shape\\nAs x ‚Üí -‚àû, sigmoid ‚Üí 0\\n\\nAs x ‚Üí +‚àû, sigmoid ‚Üí 1\\n\\nAt x = 0, sigmoid = 0.5\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Sigmoid Curve Shape\n",
    "As x ‚Üí -‚àû, sigmoid ‚Üí 0\n",
    "\n",
    "As x ‚Üí +‚àû, sigmoid ‚Üí 1\n",
    "\n",
    "At x = 0, sigmoid = 0.5\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb154ca",
   "metadata": {},
   "source": [
    "It has an S-shaped curve, like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535226f6",
   "metadata": {},
   "source": [
    "          1 |\n",
    "            |                       _______\n",
    "            |                    /\n",
    "            |                 /\n",
    "            |              /\n",
    "            |           /\n",
    "          0 |_________/_________________\n",
    "            -6      0         +6      x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df949670",
   "metadata": {},
   "source": [
    "__SIGMOID With Numpy__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4925980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      " 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95\n",
      " 96 97 98 99]\n",
      "\n",
      "Sigmoid Array\n",
      "  [0.5        0.73105858 0.88079708 0.95257413 0.98201379 0.99330715\n",
      " 0.99752738 0.99908895 0.99966465 0.99987661 0.9999546  0.9999833\n",
      " 0.99999386 0.99999774 0.99999917 0.99999969 0.99999989 0.99999996\n",
      " 0.99999998 0.99999999 1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.        ]\n",
      "\n",
      "Sigmoid Array\n",
      " [0.11920292 0.5        0.88079708]\n"
     ]
    }
   ],
   "source": [
    "# Sigmoid Function With Numpy:\n",
    "import numpy as np\n",
    "def Sigmoid(numpy_array):\n",
    "    Solution=1/(1+np.exp(-(numpy_array)))\n",
    "    return Solution\n",
    "\n",
    "#1 Example\n",
    "A=np.arange(100)\n",
    "sigmoid_array=Sigmoid(A)\n",
    "print(A)\n",
    "print(\"\\nSigmoid Array\\n \",sigmoid_array)\n",
    "\n",
    "#2 example\n",
    "print(\"\\nSigmoid Array\\n\",Sigmoid(np.array([-2, 0, 2])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117d6b83",
   "metadata": {},
   "source": [
    "__Sigmoid USed IN ML in__\n",
    "  - Logistic Regression\n",
    "  - Neural Networks\n",
    "  - Binary Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94006861",
   "metadata": {},
   "source": [
    "-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9bda8a",
   "metadata": {},
   "source": [
    "2. __MSE (Mean Squared Error )__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9862d3fe",
   "metadata": {},
   "source": [
    "MSE measures the average squared difference between the predicted values and actual (true) values.\n",
    "\n",
    "- linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34aee4ea",
   "metadata": {},
   "source": [
    "$$\n",
    "\\text{MSE} = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2\n",
    "$$\n",
    "\n",
    "yi= actual/true value\n",
    "\n",
    "ùë¶^ùëñ = predicted value\n",
    "\n",
    "n = number of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "16afa580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual_Data=\n",
      " [38 44 13  9 10 12  6 16  1 17  2 13  8 46  7 26 21 38 19 21]\n",
      "Predicted_Data\n",
      " [12 43 29 30 15  5 24 24 42 31 33 23 14 42 10  8 23  2  1 18]\n"
     ]
    }
   ],
   "source": [
    "# MSE With Numpy\n",
    "np.random.seed(1)\n",
    "Actual=np.random.randint(1,50,size=20)\n",
    "Predicted=np.random.randint(1,50,size=20)\n",
    "print(\"Actual_Data=\\n\",Actual)\n",
    "print(\"Predicted_Data\\n\",Predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c33844ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEan Squared Error 339.6\n"
     ]
    }
   ],
   "source": [
    "# mse Function numpy based\n",
    "def MSE(actual,Predict):\n",
    "    return np.mean((actual-Predict)**2)\n",
    "    \n",
    "print(\"MEan Squared Error\",MSE(Actual,Predicted))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "efea4255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 26   1 -16 -21  -5   7 -18  -8 -41 -14 -31 -10  -6   4  -3  18  -2  36\n",
      "  18   3] \n",
      "\n",
      " [ 676    1  256  441   25   49  324   64 1681  196  961  100   36   16\n",
      "    9  324    4 1296  324    9] \n",
      "\n",
      " 339.6\n"
     ]
    }
   ],
   "source": [
    "# how we get the things\n",
    "print(Actual-Predicted,\"\\n\\n\",\n",
    "np.square(Actual-Predicted),\"\\n\\n\",\n",
    "np.mean(np.square(Actual-Predicted)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca35e51e",
   "metadata": {},
   "source": [
    "---------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67ffa1e",
   "metadata": {},
   "source": [
    "__Why Use Cross-Entropy? In ML__\n",
    "\n",
    "1.Binary Classification\t          ->Binary Cross-Entropy\n",
    "\n",
    "2.Multi-Class (One label)\t      ->Categorical Cross-Entropy\n",
    "\n",
    "3.Multi-Label\t                  ->Binary Cross-Entropy (per label)__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edcad6b",
   "metadata": {},
   "source": [
    "1. __Binary --- Cross-ENtopy Loss (Log Loss)__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27fc7fff",
   "metadata": {},
   "source": [
    "\n",
    "Cross-entropy loss also known as log loss is a metric used in machine learning to measure the performance of a classification model..\n",
    "Cross-Entropy Loss (a.k.a. Log Loss) measures the difference between actual labels and predicted probabilities. It‚Äôs used when:\n",
    "\n",
    "You‚Äôre predicting class probabilities\n",
    "\n",
    "Typically applied in binary and multi-class classification\n",
    "\n",
    "- logical Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84aa3951",
   "metadata": {},
   "source": [
    "__Formula__\n",
    "$$\n",
    "\\text{Binary Cross-Entropy (BCE)} = - \\frac{1}{n} \\sum_{i=1}^{n} \\left[ y_i \\cdot \\log(\\hat{y}_i) + (1 - y_i) \\cdot \\log(1 - \\hat{y}_i) \\right]\n",
    "$$\n",
    "Where:\n",
    "\n",
    "ùëõ = number of samples\n",
    "\n",
    "ùë¶ùëñ ‚àà{0 ,1} = true label\n",
    "\n",
    "ùë¶^ùëñ‚àà(0,1): predicted probability (from sigmoid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8d1dd50a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.00000000e-09 5.00000000e-01 9.99999999e-01]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "np.clip(array,min_value,max_value)\n",
    "It restricts all values in the array to be between min_val and max_val.\"\"\"\n",
    "import numpy as np\n",
    "\n",
    "arr = np.array([0.0, 0.5, 1.0])\n",
    "clipped = np.clip(arr, 1e-9, 1 - 1e-9)\n",
    "\n",
    "print(clipped)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "41a2bb9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14462152754328741\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def binary_cross_entropy(true, pred):\n",
    "    # Avoid log(0) by clipping values to avoid the 0 in our predicted we use the clip\n",
    "    pred = np.clip(pred, 1e-9, 1 - 1e-9)\n",
    "    return -np.mean(true * np.log(pred) + (1 - true) * np.log(1 - pred))\n",
    "\n",
    "# Example\n",
    "true = np.array([1, 0, 1])\n",
    "pred = np.array([0.9, 0.1, 0.8])\n",
    "\n",
    "print(binary_cross_entropy(true, pred))  # Low loss = good prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52302c36",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a9d3cd",
   "metadata": {},
   "source": [
    "2. Categorical Cross-Entropy Loss (Multi-Class with Softmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7d368e",
   "metadata": {},
   "source": [
    "$$\n",
    "\\text{Categorical Cross-Entropy (CCE)} = - \\frac{1}{n} \\sum_{i=1}^{n} \\sum_{c=1}^{C} y_{i,c} \\cdot \\log(\\hat{y}_{i,c})\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bb917322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CCE Loss: 0.2797765635793423\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def categorical_cross_entropy(y_true, y_pred):\n",
    "    # Clip predicted values to avoid log(0)\n",
    "    y_pred = np.clip(y_pred, 1e-9, 1 - 1e-9)\n",
    "    return -np.mean(np.sum(y_true * np.log(y_pred), axis=1))\n",
    "\n",
    "# Example: 3 samples, 3 classes\n",
    "y_true = np.array([\n",
    "    [1, 0, 0],  # Class 0\n",
    "    [0, 1, 0],  # Class 1\n",
    "    [0, 0, 1]   # Class 2\n",
    "])\n",
    "\n",
    "y_pred = np.array([\n",
    "    [0.9, 0.05, 0.05],   # Correct (high confidence)\n",
    "    [0.1, 0.8, 0.1],     # Correct\n",
    "    [0.2, 0.2, 0.6]      # Correct\n",
    "])\n",
    "\n",
    "loss = categorical_cross_entropy(y_true, y_pred)\n",
    "print(\"CCE Loss:\", loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8911121",
   "metadata": {},
   "source": [
    "[Day6](./NumpyDay6.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
